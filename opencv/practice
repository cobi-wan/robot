# Python program to implement
# Webcam Motion Detector

# importing OpenCV, time and Pandas library
import cv2, time, pandas
# importing datetime class from datetime library
from datetime import datetime

# Assigning our static_back to None
static_back = None

# List when any moving object appear
motion_list = [ None, None ]

# Time of movement
time = []

# Initializing DataFrame, one column is start
# time and other column is end time
df = pandas.DataFrame(columns = ["Start", "End"])   

# Capturing video
video = cv2.VideoCapture(0)

# Infinite while loop to treat stack of image as video
while True:
	# Reading frame(image) from video
	check, frame = video.read()

	# Initializing motion = 0(no motion)
	motion = 0

	# Converting color image to gray_scale image
	gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

	# Converting gray scale image to GaussianBlur
	# so that change can be find easily
	gray = cv2.GaussianBlur(gray, (21, 21), 0)

	# In first iteration we assign the value
 	# of static_back to our first frame
	if static_back is None:
		static_back = gray
		continue

	# Difference between static background
	# and current frame(which is GaussianBlur)
	diff_frame = cv2.absdiff(static_back, gray)

	# If change in between static background and
	# current frame is greater than 30 it will show white color(255)
	thresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1]
	thresh_frame = cv2.dilate(thresh_frame, None, iterations = 2)

	# Finding contour of moving object
	cnts,_ = cv2.findContours(thresh_frame.copy(),
					cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

	# loop over the contours
    for contour in cnts:
        (x,y,w,h) = cv2.boundingRect(contour)
        if cv2.contourArea(contour)>700 and (x <= 840) and (y >= 150 and y <=350): 
            
                cv2.rectangle(Prev_frame, (x, y), (x + w, y + h), (255, 255, 0), 3)
                motion+=1
                cv2.putText(Prev_frame, f'person {motion} area {cv2.contourArea(cnt)}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)
                
    
    cv2.line(Prev_frame, (0, 150),(840,150),(0, 0,255), 4)
    cv2.line(Prev_frame, (0, 350),(840,350),(0, 0, 255),4)
    cv2.imshow("feed", Prev_frame)
    cv2.imwrite("frame%d.jpg" % frame_count , Prev_frame)
      
    
    Prev_frame=Current_frame
   
    if ret == False:
        break
    if cv2.waitKey(1) == ord('q'):
        break
    
video.release()
cv2.destroyAllWindows()